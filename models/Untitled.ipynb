{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd6d51da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# generator & discriminator\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,num_filters=64):\n",
    "        super(ResidualBlock,self).__init__()\n",
    "        self.layers=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_filters,out_channels=num_filters,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(num_features=num_filters),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_channels=num_filters,out_channels=num_filters,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(num_features=num_filters)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.layers(x)+x\n",
    "        \n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_residual_block=16,\n",
    "                 residual_channels=64):\n",
    "        super(Generator,self).__init__()\n",
    "        self.num_residual_block=num_residual_block\n",
    "        \n",
    "        self.conv1=nn.Sequential(nn.Conv2d(in_channels=1,\n",
    "                                         out_channels=residual_channels,\n",
    "                                         kernel_size=9,stride=1,\n",
    "                                         padding=4),\n",
    "                                 nn.PReLU())\n",
    "        \n",
    "        conv2=nn.ModuleList()\n",
    "        for n in range(self.num_residual_block):\n",
    "            #conv2.append(self._residual_block(num_filters=residual_channels))\n",
    "            conv2.append(ResidualBlock(num_filters=residual_channels))\n",
    "        self.conv2=conv2\n",
    "        \n",
    "        self.conv3=nn.Sequential(nn.Conv2d(in_channels=residual_channels,\n",
    "                                      out_channels=residual_channels,\n",
    "                                      kernel_size=3,\n",
    "                                      stride=1,\n",
    "                                      padding=1),\n",
    "                            nn.BatchNorm2d(num_features=residual_channels))\n",
    "        conv4=[]\n",
    "        for layer in range(3):\n",
    "            conv4+=[nn.Conv2d(in_channels=residual_channels,\n",
    "                              out_channels=residual_channels*4, \n",
    "                              kernel_size=3, \n",
    "                              stride=1, \n",
    "                              padding=1), \n",
    "                            nn.PixelShuffle(upscale_factor=2),\n",
    "                            nn.PReLU()]\n",
    "        self.conv4=nn.Sequential(*conv4)\n",
    "        \n",
    "        #self.conv5=nn.Sequential(nn.Conv2d(in_channels=64,\n",
    "        #                              out_channels=256, kernel_size=3, stride=1, padding=1), \n",
    "        #                    nn.PixelShuffle(upscale_factor=2),\n",
    "        #                    nn.PReLU())\n",
    "        self.conv5=nn.Sequential(nn.Conv2d(in_channels=64,out_channels=1,kernel_size=9,padding=4,stride=1),\n",
    "                                 nn.Tanh())\n",
    "                        \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        old_x=x\n",
    "        for layer in self.conv2:\n",
    "            x=layer(x)\n",
    "        \n",
    "        x=self.conv3(x)+old_x\n",
    "        x=self.conv4(x)\n",
    "        x=self.conv5(x)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels=1,\n",
    "                 filters=[64,128,256,512]):\n",
    "        super(Discriminator,self).__init__()\n",
    "        \n",
    "        layers=nn.ModuleList()\n",
    "        old_filter=in_channels\n",
    "        for idx,new_filter in enumerate(filters):\n",
    "            layers+=[self._blocks(old_filter,new_filter,stride=1,batchnorm=(idx>0))]\n",
    "            layers+=[self._blocks(new_filter,new_filter,stride=2,batchnorm=True)]\n",
    "            old_filter=new_filter\n",
    "        \n",
    "        self.conv=layers\n",
    "        \n",
    "        #self.linear=nn.Sequential(nn.Linear(filters[-1],1024),\n",
    "        #                          nn.LeakyReLU(0.2),\n",
    "        #                          nn.Linear(1024,1),\n",
    "        #                          nn.Sigmoid())\n",
    "        \n",
    "        self.conv2=nn.Sequential(nn.Conv2d(filters[-1],1,kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.Sigmoid())\n",
    "        \n",
    "    def _blocks(self,in_channels=64,out_channels=128,stride=1,batchnorm=True):\n",
    "        layers=[]\n",
    "        layers.append(nn.Conv2d(in_channels=in_channels,\n",
    "                                              out_channels=out_channels, \n",
    "                                              kernel_size=3,\n",
    "                                              stride=stride,\n",
    "                                              padding=1))\n",
    "                     \n",
    "        if batchnorm : layers.append(nn.BatchNorm2d(num_features=out_channels))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "        layers=nn.Sequential(*layers)\n",
    "        return layers\n",
    "    \n",
    "    def forward(self,x):\n",
    "        for layers in self.conv:\n",
    "            x=layers(x)\n",
    "        #x=x.reshape(-1,x.shape[1]*x.shape[2]*x.shape[3])\n",
    "        #print(x.shape)\n",
    "        x=self.conv2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e30001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 128, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 8, 8])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen=Generator()\n",
    "z=torch.randn(2,1,16,16)\n",
    "z=gen(z.to(torch.float32))\n",
    "print(z.shape)\n",
    "d=Discriminator()\n",
    "d(z).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06275639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
